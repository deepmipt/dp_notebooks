{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPavlov - an Open-Source Conversational AI Framework \n",
    "---\n",
    "\n",
    "[DeepPavlov](https://deeppavlov.ai/) Library is a conversational open-source library for Natural Language Processing (NLP) and Multiskill AI Assistant development. DeepPalvov is based on TensorFlow, Keras. And now it supports PyTorch. Moreover DeepPavlov supports Transformers from  Hugging face to enable you to use a wide variety of transformer-based models and Datasets from Hugging face with hundreds of datasets to train your model. \n",
    "\n",
    "You can read more about us in our [official blog](https://medium.com/deeppavlov). Also, feel free to test our BERT-based models by using our [demo](http://demo.deeppavlov.ai). And don’t forget DeepPavlov has a dedicated [forum](https://forum.deeppavlov.ai/), where any questions concerning the library and the models are welcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://static.tildacdn.com/tild3762-3666-4530-b139-666433343863/_DeepPavlov_-5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "We support `Linux` and `Windows` platforms, `Python 3.6` and `Python 3.7`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deeppavlov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuickStart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [DeepPavlov](https://deeppavlov.ai/) NLP pipelines are defined in the separate configuration files under the *config/faq* folder. List of models is available on\n",
    "[the doc page](http://docs.deeppavlov.ai/en/master/features/overview.html)\n",
    "\n",
    "When you are decided on the model and a configuration file, there are two ways to use it\n",
    "\n",
    "* via **Command Line Interface (CLI)**\n",
    "* via **Python**\n",
    "* via **Rise API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use DeepPavlov Text Classification in CLI\n",
    "\n",
    "Let’s demonstrate the DeepPavlov text classification models using the insult detection problem. It involves predicting whether a comment posted during a public discussion is considered insulting to one of the participants. Basically, this is a binary classification problem with only two classes: *Insult* and *Not Insult*. \n",
    "\n",
    "\n",
    "Before using the model you should install all it's requirements by running `install`. You can retrain the model by running it with `train` command. To get predictions from a model interactively through CLI, run `interact`. Dataset will be downloaded if `-d` flag is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m deeppavlov install insults_kaggle_bert_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m deeppavlov train insults_kaggle_bert_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m deeppavlov interact insults_kaggle_bert_torch -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The detailed description of the commands can be found in our docs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepPavlov for Text Classification in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to interact with the model first you need to `build_model` the model. The `download=True` parameter indicates that we want to build already pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import build_model, configs\n",
    "model = build_model(configs.classifiers.insults_kaggle_bert_torch, download=True)\n",
    "model(['hey, how are you?', 'You are so dumb!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can evaluate the model by running `evaluate_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import evaluate_model\n",
    "performance = evaluate_model(configs.classifiers.insults_kaggle_bert_torch)\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to train the model on your data you need to change `data_path` to folder with *train.csv*, *valid.csv*, *test.csv* and change `MODEL_PATH` where to save trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_name': 'basic_classification_reader',\n",
      " 'data_path': '{DOWNLOADS_PATH}/insults_data',\n",
      " 'x': 'Comment',\n",
      " 'y': 'Class'}\n",
      "{'DOWNLOADS_PATH': '{ROOT_PATH}/downloads',\n",
      " 'MODELS_PATH': '{ROOT_PATH}/models',\n",
      " 'MODEL_PATH': '{MODELS_PATH}/classifiers/insults_kaggle_torch_bert',\n",
      " 'ROOT_PATH': '~/.deeppavlov',\n",
      " 'TRANSFORMER': 'bert-base-uncased'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from deeppavlov import configs\n",
    "config = json.load(open(configs.classifiers.insults_kaggle_bert_torch))\n",
    "\n",
    "pprint(config['dataset_reader'])\n",
    "pprint(config['metadata']['variables'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import train_model\n",
    "model = train_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepPavlov with Transformers support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the text classification model performance depends on the transformer architecture. Before doing so, let's make sure that we include the transformer name to the default model path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.deeppavlov/classifiers/insults_kaggle_torch_bert                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['metadata']['variables']['MODEL_PATH'] = \"{MODELS_PATH}/classifiers/insults_kaggle_torch_bert/{TRANSFORMER}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the performance for three transformers `albert-base-v2`, `distilbert-base-uncased`, `bert-base-uncased`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "from deeppavlov import train_model\n",
    "results = {}\n",
    "\n",
    "transformers = ['albert-base-v2', 'distilbert-base-uncased', 'bert-base-uncased']\n",
    "for transformer in transformers:\n",
    "    config['metadata']['variables']['MODEL_PATH'] = \"{MODELS_PATH}/classifiers/insults_kaggle_torch_bert/{TRANSFORMER}\"\n",
    "    config['metadata']['variables']['TRANSFORMER'] = transformer\n",
    "    model = train_model(config, download=False)\n",
    "    results[transformer] = evaluate_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'albert-base-v2': {'train': OrderedDict([('roc_auc', 0.9763),\n",
       "               ('accuracy', 0.9412),\n",
       "               ('f1_macro', 0.9231)]),\n",
       "  'valid': OrderedDict([('roc_auc', 0.9223),\n",
       "               ('accuracy', 0.875),\n",
       "               ('f1_macro', 0.8324)]),\n",
       "  'test': OrderedDict([('roc_auc', 0.8556),\n",
       "               ('accuracy', 0.7597),\n",
       "               ('f1_macro', 0.7508)])},\n",
       " 'distilbert-base-uncased': {'train': OrderedDict([('roc_auc', 0.9847),\n",
       "               ('accuracy', 0.9521),\n",
       "               ('f1_macro', 0.9399)]),\n",
       "  'valid': OrderedDict([('roc_auc', 0.9243),\n",
       "               ('accuracy', 0.8731),\n",
       "               ('f1_macro', 0.8373)]),\n",
       "  'test': OrderedDict([('roc_auc', 0.8641),\n",
       "               ('accuracy', 0.7826),\n",
       "               ('f1_macro', 0.7788)])},\n",
       " 'bert-base-uncased': {'train': OrderedDict([('roc_auc', 0.9813),\n",
       "               ('accuracy', 0.9445),\n",
       "               ('f1_macro', 0.9309)]),\n",
       "  'valid': OrderedDict([('roc_auc', 0.9318),\n",
       "               ('accuracy', 0.867),\n",
       "               ('f1_macro', 0.8357)]),\n",
       "  'test': OrderedDict([('roc_auc', 0.866),\n",
       "               ('accuracy', 0.7902),\n",
       "               ('f1_macro', 0.7887)])}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'albert-base-v2': {'train': OrderedDict([('roc_auc', 0.9763),\n",
    "               ('accuracy', 0.9412),\n",
    "               ('f1_macro', 0.9231)]),\n",
    "  'valid': OrderedDict([('roc_auc', 0.9223),\n",
    "               ('accuracy', 0.875),\n",
    "               ('f1_macro', 0.8324)]),\n",
    "  'test': OrderedDict([('roc_auc', 0.8556),\n",
    "               ('accuracy', 0.7597),\n",
    "               ('f1_macro', 0.7508)])},\n",
    " 'distilbert-base-uncased': {'train': OrderedDict([('roc_auc', 0.9847),\n",
    "               ('accuracy', 0.9521),\n",
    "               ('f1_macro', 0.9399)]),\n",
    "  'valid': OrderedDict([('roc_auc', 0.9243),\n",
    "               ('accuracy', 0.8731),\n",
    "               ('f1_macro', 0.8373)]),\n",
    "  'test': OrderedDict([('roc_auc', 0.8641),\n",
    "               ('accuracy', 0.7826),\n",
    "               ('f1_macro', 0.7788)])},\n",
    " 'bert-base-uncased': {'train': OrderedDict([('roc_auc', 0.9813),\n",
    "               ('accuracy', 0.9445),\n",
    "               ('f1_macro', 0.9309)]),\n",
    "  'valid': OrderedDict([('roc_auc', 0.9318),\n",
    "               ('accuracy', 0.867),\n",
    "               ('f1_macro', 0.8357)]),\n",
    "  'test': OrderedDict([('roc_auc', 0.866),\n",
    "               ('accuracy', 0.7902),\n",
    "               ('f1_macro', 0.7887)])}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's aggregate the performance on the test set for different transformer-based models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Transformer | ROC-AUC | Accuracy | F1-macro\n",
    "| --- | --- | --- | --- |\n",
    "| bert-base-uncased | **0.866** | **0.7902** | **0.788** |\n",
    "| albert-base-v2 |  0.8556 | 0.7597 | 0.7508 |\n",
    "| distilbert-base-uncased |  0.8641 | 0.7826 | 0.7788  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Links\n",
    "---\n",
    "\n",
    "[DeepPavlov Repository](https://github.com/deepmipt/DeepPavlov)\n",
    "\n",
    "[DeepPavlov Demo Page](https://demo.deeppavlov.ai)\n",
    "\n",
    "[DeepPavlov Documentation](https://docs.deeppavlov.ai)\n",
    "\n",
    "[Our Forum](https://forum.deeppavlov.ai)\n",
    "\n",
    "[Our Medium](https://medium.com/deeppavlov)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
